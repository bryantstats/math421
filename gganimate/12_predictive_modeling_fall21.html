<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title> Predictive Modeling: Tuning</title>
    <meta charset="utf-8" />
    <meta name="author" content=" Son Nguyen " />
    <script src="libs/header-attrs-2.16/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <img src="figures/bat-cartoon.png" /> Predictive Modeling: Tuning
]
.author[
### <font size="5"> Son Nguyen </font>
]

---


&lt;style&gt;

.remark-slide-content {
  background-color: #FFFFFF;
  border-top: 80px solid #F9C389;
  font-size: 17px;
  font-weight: 300;
  line-height: 1.5;
  padding: 1em 2em 1em 2em
}

.inverse {
  background-color: #696767;
  border-top: 80px solid #696767;
  text-shadow: none;
  background-image: url(https://github.com/goodekat/presentations/blob/master/2019-isugg-gganimate-spooky/figures/spider.png?raw=true);
	background-position: 50% 75%;
  background-size: 150px;
}

.your-turn{
  background-color: #8C7E95;
  border-top: 80px solid #F9C389;
  text-shadow: none;
  background-image: url(https://github.com/goodekat/presentations/blob/master/2019-isugg-gganimate-spooky/figures/spider.png?raw=true);
	background-position: 95% 90%;
  background-size: 75px;
}

.title-slide {
  background-color: #F9C389;
  border-top: 80px solid #F9C389;
  background-image: none;
}

.title-slide &gt; h1  {
  color: #111111;
  font-size: 40px;
  text-shadow: none;
  font-weight: 400;
  text-align: left;
  margin-left: 15px;
  padding-top: 80px;
}
.title-slide &gt; h2  {
  margin-top: -25px;
  padding-bottom: -20px;
  color: #111111;
  text-shadow: none;
  font-weight: 300;
  font-size: 35px;
  text-align: left;
  margin-left: 15px;
}
.title-slide &gt; h3  {
  color: #111111;
  text-shadow: none;
  font-weight: 300;
  font-size: 25px;
  text-align: left;
  margin-left: 15px;
  margin-bottom: -30px;
}

&lt;/style&gt;

&lt;style type="text/css"&gt;
.left-code {
  color: #777;
  width: 48%;
  height: 92%;
  float: left;
}
.right-plot {
  width: 51%;
  float: right;
  padding-left: 1%;
}
&lt;/style&gt;




---
# Model Tuning

---
# Data Preparation


```r
library(tidyverse)
library(caret)

df = read_csv("https://bryantstats.github.io/math421/data/titanic.csv")

# Remove some columns
df &lt;- df %&gt;% select(-PassengerId, -Ticket, -Name, -Cabin)


# Set the target variable
df &lt;- df %&gt;% rename(target=Survived)

# Correct variables' types
df &lt;- df %&gt;% 
  mutate(target = as.factor(target),
         Pclass = as.factor(Pclass),
         )


# Handle missing values
df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)

df = drop_na(df)

splitIndex &lt;- createDataPartition(df$target, p = .70, 
                                  list = FALSE)
df_train &lt;- df[ splitIndex,]
df_test &lt;- df[-splitIndex,]
```

---
# Tree 1

.left-code[

```r
library(rpart)
tree1&lt;-rpart(target ~ ., 
            data = df_train,
*           control=rpart.control(maxdepth=2))

# Plot the tree
library(rattle)
fancyRpartPlot(tree1)
```
]
.right-plot[
&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Tree 2

.left-code[

```r
library(rpart)
tree2&lt;-rpart(target ~ ., 
            data = df_train,
*           control=rpart.control(maxdepth=3))

# Plot the tree
library(rattle)
fancyRpartPlot(tree2)
```
]
.right-plot[
&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;
]

---
# Tree 3

.left-code[

```r
library(rpart)
tree3&lt;-rpart(target ~ ., 
            data = df_train,
*           control=rpart.control(maxdepth=5))

# Plot the tree
library(rattle)
fancyRpartPlot(tree3)
```
]
.right-plot[
&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;
]



---
# What value maxdepth should be?

- maxdepth is called hyperparameter

---
# What value maxdepth should be?

- maxdepth is called hyperparameter

- The modeler must decide the values of hyperparameter

---
# What value maxdepth should be?

- maxdepth is called hyperparameter

- The modeler must decide the values of hyperparameter

- What is the best value for maxdepth? 


---
# Approach 1:  Test them on the test




- We cheated a little bit by using the test data for hyperparameter tuning

- This is not recommended! 

---
# Approach 2: Cross validation

![](grid_search_cross_validation.png)

---
# Approach 2 with Caret


```r
# Decide the range of the maxdepth to search for the best
tuneGrid = expand.grid(maxdepth = 2:10)

# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
                         number = 10)


# Do Approach 2 
tree_approach2 &lt;- train(target~., data=df_train, 
                                method = "rpart2", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)
```

---
# Approach 2 with Caret


```r
# Plot the results
plot(tree_approach2)
```

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---
# Approach 2 with Caret


```r
# Plot the results
print(tree_approach2)
```

```
## CART 
## 
## 623 samples
##   7 predictor
##   2 classes: '0', '1' 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold) 
## Summary of sample sizes: 561, 562, 561, 561, 560, 561, ... 
## Resampling results across tuning parameters:
## 
##   maxdepth  Accuracy   Kappa    
##    2        0.8059849  0.5806503
##    3        0.8140238  0.5956839
##    4        0.8221139  0.6166437
##    5        0.8237277  0.6156180
##    6        0.8157912  0.5956380
##    7        0.8157912  0.5956380
##    8        0.8157912  0.5956380
##    9        0.8157912  0.5956380
##   10        0.8157912  0.5956380
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was maxdepth = 5.
```

---
# Evaluate the tuned model

- By default, the tuned model will go with the `maxdepth` that gives the highest accuracy. 


```r
pred &lt;- predict(tree_approach2, df_test)

cm &lt;- confusionMatrix(data = pred, reference = df_test$target, positive = "1")

cm$overall[1]
```

```
##  Accuracy 
## 0.8082707
```

---
- Caret tunes models by default even if you don't set the tuneGrid


```r
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
                         number = 10)
# Do Approach 2 
tree_approach2_new &lt;- train(target~., data=df_train, 
                                method = "rpart2", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)
# Plot the results
plot(tree_approach2_new)
```

---
- Caret tunes models by default even if you don't set the tuneGrid, for example:

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---
# What are other approaches?


```r
?trainControl
```

---
# What other hyperparameters I can tune?

- Go to https://topepo.github.io/caret/available-models.html

- Then search for the name of the method. 

- OR



```r
getModelInfo('rpart2')$rpart$parameters
```

```
##   parameter   class          label
## 1  maxdepth numeric Max Tree Depth
```


# Data Preparation


```r
library(tidyverse)
library(rpart)
df = read_csv("../data/titanic.csv")

# Set the target variable
names(df)[8] &lt;- 'target'

# Remove some columns
df &lt;- df %&gt;% select(-PassengerId, -Ticket, -Name, -Cabin)

# Correct variables' types
df$target &lt;- factor(df$target)
df$Pclass = factor(df$Pclass)
df$Sex &lt;- factor(df$Sex)
df$Embarked &lt;- factor(df$Embarked)

# Handle missing values
df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)

df = drop_na(df)

# Split the data to train and test
library(caret)
set.seed(00000)
splitIndex &lt;- createDataPartition(df$target, p = .90, 
                                  list = FALSE)
df_train &lt;- df[ splitIndex,]
df_test &lt;- df[-splitIndex,]
```


---
# Random Forest

- What hyperparameters can we tune?


```r
getModelInfo('rf')$rf$parameters
```

```
##   parameter   class                         label
## 1      mtry numeric #Randomly Selected Predictors
```

-  As shown, `mtry` is the only tuning parameter that method `rf` offers. 

---
# Random Forest

- Tuning `mtry` using Cross-Validation


```r
# Decide the range of the mtry to search for the best
tuneGrid = expand.grid(mtry = 2:4)

# Tell caret to do 10 - fold cross-Validation
trControl = trainControl(method = "cv",
                         number = 10)


# train a forest using above setup
forest_rf &lt;- train(target~., data=df_train, 
                                method = "rf", 
                                trControl = trControl,
                                tuneGrid = tuneGrid)
```


---
# Random Forest


```r
plot(forest_rf)
```

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

---
# Random Forest with Ranger

- If you want to tune other hyperparameter, you may want to look at different method for random forest. 

- Random Forest can be implemented by method `ranger`

- Let's check to see what parameters we can tune with `ranger` method


```r
getModelInfo('ranger')$ranger$parameters
```

```
##       parameter     class                         label
## 1          mtry   numeric #Randomly Selected Predictors
## 2     splitrule character                Splitting Rule
## 3 min.node.size   numeric             Minimal Node Size
```

- As shown, `ranger` offer to tune three hyperparameters for random forest: `mtry`, `splitrule` and `min.node.size`. 

---
# Tune

- Tune `mtry`, `splitrule` and `min.node.size`. 


```r
trControl = trainControl(method = "cv",
                         number = 10)

tuneGrid = expand.grid(mtry = 2:4,
                       splitrule = c('gini', 'extratrees'),
                       min.node.size = c(1:10))

forest_ranger &lt;- train(target~., data=df_train, 
                    method = "ranger", 
                    trControl = trControl,
                    tuneGrid = tuneGrid)
```

---
# Tune


```r
plot(forest_ranger)
```

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;

---
# Evaluate the tuned model

- The tuning process is done on the training data.  

- The tuned model have never seen the testing data.  Let's evaluate the tuned model the testing data


```r
pred &lt;- predict(forest_ranger, df_test)

cm &lt;- confusionMatrix(data = pred, reference = df_test$target, positive = "1")

cm$overall[1]
```

```
##  Accuracy 
## 0.8372093
```

---
- Caret tunes models by default even if you don't set the tuneGrid, for example:


```r
trControl = trainControl(method = "cv",
                         number = 10)
forest_ranger &lt;- train(target~., data=df_train, 
                    method = "ranger", 
                    trControl = trControl)
plot(forest_ranger)
```

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;


---
class: inverse, middle, center
# Model Comparison


---
# Model Comparison

Let's compare different models: Decision Tree, Random Forest and Linear Discriminant Analysis. 


```r
trControl = trainControl(method = "cv",
                         number = 10)

tree &lt;- train(target~., data=df_train, 
                                method = "rpart2", 
                                trControl = trControl)

forest_ranger &lt;- train(target~., data=df_train, 
                    method = "ranger", 
                                trControl = trControl)

lda &lt;- train(target~., data=df_train, 
                                method = "lda", 
                                trControl = trControl)

results &lt;- resamples(list('Decision Tree' = tree,
                          'Random Forest' = forest_ranger,
                          'LDA'= lda))

bwplot(results)
```

---
# Model Comparison

&lt;img src="12_predictive_modeling_fall21_files/figure-html/unnamed-chunk-25-1.png" style="display: block; margin: auto;" /&gt;


---
# Final Model

- The comparison shows that random forest using `ranger` package is the best out of the three.  

- This comparison is done on training data.  The models have never seen the test data. 

- Let's evaluate this model on the test data


```r
pred &lt;- predict(forest_ranger, df_test)

cm &lt;- confusionMatrix(data = pred, reference = df_test$target, positive = "1")

cm$overall[1]
```

```
##  Accuracy 
## 0.8139535
```


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "<div class=\"progress-bar-container\">\n  <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n  </div>\n</div>`"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
