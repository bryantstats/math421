x-y
x*y
x/y
x
x^2
log(x)
?log
mean(x)
sum(x)
median(x)
sd(x)
min(x)
max(x)
summary(x)
?summary
x <- c(1:2020)
x
x <- c(-2020:2020)
x
x <- rep(1, 1000)
x
x <- rep(c(1,2), 1000)
x
?c
x <- c(1,1,2,3)
x <- (1,1,2,3)
x <- c(1:2020)
sum(x)
sum(c(1:2020))
x <- c(1:2020)
sum(x^2)
sum(x^3)/2020
mean(x^3)
?mean
c(1:10)
seq(1:11, 2)
seq(1, 11, 2)
seq(1, 11, 2)
seq(1, 100, 2)
?seq
x <- c(1, 2019, 2)
x
x <- seq(1, 2019, 2)
x
y <- seq(2, 2020, 2)
x*y
sum(x*y)
x <- c(1:2020)
y <- c(2:2021)
sum(x/y)
x <- c(1:100)^2
x
1/x
sum(1/x)
x <- c(1:1000)^2
sum(1/x)
x <- c(1:10000)^2
sum(1/x)
x <- c(1:100000)^2
sum(1/x)
x <- c(1:2020)
x <- c(1:2020)
# How to create a sequence
x <- rep(c(1,2), 1000)
seq(1:11, 2)
seq(1, 11, 2)
seq(1, 11, 2)
seq(1, 100, 2)
x <- rep(c(1,2), 1000)
seq(1:11, 2)
seq(1, 11, 2)
seq(1, 11, 2)
seq(1, 100, 2)
x <- c(1:2020)
sum(x^2020)
-.1*log(.1, 2)-.9*log(.9, 2)
log(4,2)
-.1*log(.5, 2)-.9*log(.5, 2)
-.1*log(.01, 2)-.9*log(.99, 2)
-.01*log(.01, 2)-.99*log(.99, 2)
knitr::opts_chunk$set(message = FALSE)
library(tidyverse)
df <- read_csv('https://covidtracking.com/data/download/all-states-history.csv')
library(lubridate)
df$date <- ymd(df$date)
class(df$date)
df$month = month(df$date)
# day of the week
df$weekday = wday(df$date)
# day of the month
df$monthday <- mday(df$date)
library(tidyverse)
df$daily_death <- case_when(
df$deathIncrease <3 ~ 'low',
df$deathIncrease <=14 ~ 'medium',
TRUE ~ 'high'
)
library(tidyverse)
x <- c(1:10)
# square root of x
# sqrt(x)
x %>% sqrt
sum(sqrt(x))
x %>% sqrt %>% sum
log(sum(sqrt(x)))
x %>% sqrt %>% sum %>% log
# log base 2 of 16
log(16, 2)
16 %>% log(2)
df %>%
group_by(dataQualityGrade) %>%
summarise(mean(positiveIncrease))
df %>%
group_by(dataQualityGrade) %>%
summarise(median(positiveIncrease))
df %>%
group_by(dataQualityGrade) %>%
summarise(max(positiveIncrease))
df$month3 <- case_when(df$monthday<=10 ~ 'early_month',
df$monthday <=20 ~ 'mid_month',
TRUE ~'end_month')
df %>%
group_by(dataQualityGrade) %>%
summarise(mean(month2))
df
df %>%
group_by(dataQualityGrade) %>%
summarise(mean(month2))
df$dataQualityGrade
table(df$dataQualityGrade)
df %>%
group_by(dataQualityGrade) %>%
summarise(mean(positiveIncrease))
df %>%
group_by(dataQualityGrade) %>%
summarise(mean(weekday))
df %>%
group_by(weekday) %>%
summarise(mean(positiveIncrease))
df %>%
group_by(month3) %>%
summarise(mean(positiveIncrease))
install.packages('gapminder')
library(tidyverse)
source('C:/Users/snguyen4/Dropbox/git/math421/who.R')
source('C:/Users/snguyen4/Dropbox/git/math421/who.R')
p1
source('C:/Users/snguyen4/Dropbox/git/math421/who.R')
install.packages('gifski')
p1
save.image("~/1.RData")
x <- 2
save.image("~/1.RData")
load("~/1.RData")
library(shiny); runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a9_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a9_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a9_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a9_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a2_3.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
runApp('C:/Users/snguyen4/Dropbox/git/math421/gganimate/shiny_fa20/a9_demonstration/a2_1.R')
-log(.07)
-log(.01)
-log(.001)
-log(.00000001)
library(ggplot2)
library(gganimate)
ggplot(mtcars, aes(factor(cyl), mpg)) +
geom_boxplot() +
# Here comes the gganimate code
transition_states(
gear,
transition_length = 2,
state_length = 1
) +
enter_fade() +
exit_shrink() +
ease_aes('sine-in-out')
library(caret)
install.packages('caret')
?trainControl
library(caret)
?trainControl
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(tidytext)
library(knitr)
df <- readr::read_csv('data/netflix_titles.csv')
df %>%
head(2) %>%
kable()
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
library(textrecipes)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
library(textrecipes)
library(tidytext)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
library(textrecipes)
library(tidytext)
library(tidyverse)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
??step_smote
library(textrecipes)
library(tidytext)
library(tidyverse)
library(themis)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df <- juice(a)
# Using Caret for modeling
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .1,
list = FALSE)
library(textrecipes)
library(tidytext)
library(tidyverse)
library(themis)
library(caret)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
mutate(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df <- juice(a)
# Using Caret for modeling
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .1,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
forest_ranger <- train(target~., data=df_train,
method = "ranger")
pred <- predict(forest_ranger, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
d = data.frame(pred = pred, obs = df_test$target)
library(yardstick)
d %>% conf_mat(pred, obs) %>% autoplot
d %>% conf_mat(pred, obs) %>% autoplot
library(textrecipes)
library(tidytext)
library(tidyverse)
library(themis)
library(caret)
df <- readr::read_csv('data/netflix_titles.csv')
# Select data and set target
df <- df %>%
rename(target = type) %>%
select(target, description) %>%
head(2)
setwd("C:/Users/snguyen4/Dropbox/git/math421/gganimate")
df <- read_csv('../data/netflix_titles.csv')
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
library(tidyverse)
library(tidytext)
library(knitr)
library(tidyverse)
library(tidytext)
library(knitr)
df <- read_csv('../data/netflix_titles.csv')
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
df
df <- read_tsv('../data/user_reviews.tsv')
df
df %>%
unnest_tokens(input = text, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
## Third Text Data
df_spam <- read_csv('../data/spam_message.csv')
df_spam
df_spam <- read_csv('../data/spam_message.csv')
df %>%
unnest_tokens(input = Message, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
df
df_spam %>%
unnest_tokens(input = Message, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
get_graph_frequency <- function()
{
}
get_graph_frequency
ggplot
get_graph_frequency <- function(text_data, text_column)
{
library(tidyverse)
library(tidytext)
library(knitr)
chart_output <- text_data %>%
unnest_tokens(input = text_column, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
return(chart_output)
}
get_graph_frequency
get_graph_frequency
df
get_graph_frequency(text_data = df, text_column = text)
get_graph_frequency <- function(text_data, text_column)
{
library(tidyverse)
library(tidytext)
library(knitr)
chart_output <- text_data %>%
unnest_tokens(input = text_data[[text_column]], output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
return(chart_output)
}
get_graph_frequency(text_data = df, text_column = text)
get_graph_frequency <- function(text_data, text_column)
{
library(tidyverse)
library(tidytext)
library(knitr)
text_data %>%
unnest_tokens(input = text_column, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
}
get_graph_frequency(text_data = df, text_column = text)
df
word_frequency <- function(text_df, text_col) {
library(tidyverse)
library(tidytext)
text_df %>%
unnest_tokens(input = text_col, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
}
word_frequency(text_df = df, text_col = text)
df
get_graph_frequency2 <- function(text_data, text_column_number)
{
library(tidyverse)
library(tidytext)
library(knitr)
text_data %>%
unnest_tokens(input = text_data[[text_column_number]], output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
}
get_graph_frequency2(text_data = df, text_column_number = 3)
df[3]
df[[3]]
get_graph_frequency2 <- function(text_data, text_column_number)
{
library(tidyverse)
library(tidytext)
library(knitr)
text_data %>%
unnest_tokens(input = text_data[text_column_number], output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
}
get_graph_frequency2(text_data = df, text_column_number = 3)
