labs(y = '', x = 'Frequency')
library(tidyverse)
library(tidytext)
library(knitr)
df <- read_csv('../data/netflix_titles.csv')
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
head(5) %>%
ggplot(aes(x = n, y = reorder(word, n))) +
geom_col() + theme(axis.text.y = element_text(size = 40))+
labs(y = '', x = 'Frequency')
rsconnect::setAccountInfo(name='sn904109',
token='05E619F75AE36AB48C8325CFEE24F669',
secret='X0d2mr1ycJlb/W9rZU6b8uQokXOBg3CtX15gM8TY')
install.packages('rsconnect')
rsconnect::setAccountInfo(name='sn904109',
token='05E619F75AE36AB48C8325CFEE24F669',
secret='X0d2mr1ycJlb/W9rZU6b8uQokXOBg3CtX15gM8TY')
phi1 - function(t){}
phi1 <- function(t){}
f1 <- function(t){}
e
exp(1)
logistic(1)
plogis(1)
1/(1+1/exp(1))
plogis(1)
tanh(1)
e
e = exp(1)
(e-1/e)/(e+1/e)
tanh(1)
# plogis is logistic function
logistic = plogis
logistic(1)
install.packages('sigmoid')
relu(1)
library(sigmoid)
relu(1)
relu(-1)
logistic(15)
tanh(-7)
.99*9
x <- c(1,2,3,4,5,6,7,8,9,10)
y <- c(80, 90, 85, 100, 120, 150, 140, 135, 170, 200)
plot(x,y)
sum(x)
sum(y)
sum(x^2)
sum(y^2)
sum(x*y)
10*8005-55*1270
((10*385-55^2)*(10*175350-1270^2))^.5
10200/10770.1
y <- c(80, 90, 85, 100, 120, 150, 140, 135, 17, 20)
plot(x,y)
cor(x, y)
y <- c(80, 90, 85, 100, 120, 150, 140, 135, 70, 80)
plot(x,y)
y <- c(80, 90, 85, 100, 60, 90, 140, 135, 130, 180)
plot(x,y)
cor(x, y)
y <- c(80, 90, 65, 10, 60, 90, 50, 40, 20, 10)
plot(x,y)
cor(x, y)
cor(x, y)
y <- c(80, 90, 65, 10, 60, 90, 50, 40, 20, 10, 0, - 1, -2, -3)
x <- c(1,2,3,4,5,6,7,8,9,10, 1, 2, 3, 0)
plot(x,y)
cor(x, y)
y = 2*x + 4
plot(x,y)
plot(x,y)
cor(x, y)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
# install.packages("ggplot2")
library(ggplot2)
library(dplyr)
# Variables
Percentage = c(.3,.2, .45, .05)
Grades = c('Final Project','Mid-term Project','Assignments','Attendance')
df = data.frame(Grades = Grades, Percentage = Percentage, labels = paste0(Percentage*100, "%"))
ggplot(df, aes(x = "", y = Percentage, fill = Grades)) +
geom_col() +
geom_label(aes(label = labels),
position = position_stack(vjust = 0.5),
show.legend = FALSE) +
labs(x='')+
coord_polar(theta = "y")+
theme_void()
library(ggplot2)
library(forcats)
# Basic barplot
Grades           = c("A","A-","B+","B","B-","C+","C","C-","D+","D", "F")
Total_Percentage = c(92.45, 89.45, 86.45, 82.45 ,79.45, 76.45, 72.45, 69.45, 66.45, 59.45, 0)
df = data.frame(Grades = Grades, Total_Percentage = Total_Percentage)
p<-ggplot(data=df, aes(x= fct_rev(fct_reorder(Grades, Total_Percentage)), y=Total_Percentage)) +
geom_col(fill="steelblue")+
labs(y = 'Total Percentage', x ='Letter Grade')+
geom_text(aes(label = Total_Percentage), vjust = -0.5)+
theme_minimal()
p
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
df
str(df)
df <-  read.csv('https://bryantstats.github.io/math421/data/us-states.csv')
str(df)
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
View(df)
str(df)
df$Date_reported = as.Date(df$Date_reported)
str(df)
df1 = df[df$Date_reported >= "2023-01-01",]
View(df1)
df1 = df[(df$Date_reported >= "2023-01-01") & (df$Country == 'Ukraine'),]
df$New_cases2 <- ifelse(df$New_cases==0,
'No_new_cases','Has_new_cases')
View(df)
table(df$New_cases2)
install.packages('dplyr')
library(dplyr)
case_when()
case_when
library(tidyverse)
?read.csv
?read_csv
sin(100)
cos(sin(100))
log(cos(sin(100)))
tan(log(cos(sin(100))))
100 %>% sin %>% cos %>% log %>% tan
tan(log(cos(sin(100))))
square(100)
squares(100)
4^3
df <- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
df
df
View(df)
max(df$date)
min(df$date)
df[df$state == 'Rhode Island',]
df1 = df[df$state == 'Rhode Island',]
mean(df1$cases, na.rm = TRUE)
df %>% filter(state == 'Rhode Island')
df %>% filter(state == 'Rhode Island') %>% summarise(average_cases = mean(cases))
df %>% filter(state == 'Rhode Island') %>% arrange(deaths)
df %>% filter(state == 'Rhode Island' | state == 'Washington') %>% group_by(state) %>% summarise(mean_death = mean(deaths))
12/25
(.3*.6)/(.3*.6+.2*.4)
(6*7)/(6*7+4*3)
1/12
df <- read_csv('https://bryantstats.github.io/math421/data/adult_census_missing.csv')
df
na_if()
na_if
?na_if
table(df$age)
table(df$workclass)
na_if(df,'Unknown')
na_if(df$workclass,'Unknown')
df$workclass2 = na_if(df$workclass,'Unknown')
table(df$workclass)
table(df$workclass2)
names(df)
df <- df %>% select(workclass) %>% na_if('Unknown')
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::use_webcam()
xaringanExtra::use_fit_screen()
library(tidyverse)
df <- read_csv('https://bryantstats.github.io/math421/data/titanic_missing.csv')
df %>% summarise(mean_age=mean(Age, na.rm=TRUE))
df %>% ggplot(aes(x=Age, color=Sex))+
geom_density()
# Missing values by columns
colSums(is.na(df))
```
colSums(is.na(df))
table(df=='Missing')
colSums(df=='Missing')
colSums(df=='Missing', na.rm = TRUE)
colSums(df=='Missing', na.rm = TRUE)
df1 <- replace(df, 'Unknown')
?replace
df1 <- replace(df,df=='Unknown', NA)
colSums(df=='Unknown', na.rm = TRUE)
colSums(df1=='Unknown', na.rm = TRUE)
colSums(is.na(df))
colSums(is.na(df1))
df1 <- replace(df, df %in% c('Unknown', 'Missing','Not Available', NA))
df1 <- replace(df, df %in% c('Unknown', 'Missing','Not Available'), NA)
# Convert Unknown, Missing and Not Available to NA
df <- replace(df, df %in% c('Unknown', 'Missing','Not Available'), NA)
?replace
df %in% c('Unknown', 'Missing','Not Available')
df
df %in% c('Unknown', 'Missing','Not Available')
df=='Unknown'
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
xaringanExtra::use_tile_view()
xaringanExtra::use_panelset()
xaringanExtra::use_webcam()
xaringanExtra::use_fit_screen()
library(tidyverse)
df <- read_csv('https://bryantstats.github.io/math421/data/titanic_missing.csv')
df %>% summarise(mean_age=mean(Age, na.rm=TRUE))
df %>% ggplot(aes(x=Age, color=Sex))+
geom_density()
# Missing values by columns
colSums(is.na(df))
```
library(VIM)
df <- read_csv('https://bryantstats.github.io/math421/data/titanic_missing.csv')
df <- replace(df, df %in% c('Unknown', 'Missing','Not Available'), NA)
df
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 2
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
View(y)
hist(y$y_bar)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 3
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 4
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 4
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 5
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 6
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 7
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 10
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 20
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT3
# Tossing a coin/Bernoulli
n1 = 1000000
# sample size
n = 100
y = sample(c(0:1), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 2
y = sample(c(0:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
View(y)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 3
y = sample(c(0:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 20
y = sample(c(0:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 100
y = sample(c(0:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 20)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 100
y = sample(c(0:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 50)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 100
y = sample(c(1:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 50)
# CLT2
#  Rolling a die
n1 = 1000000
# sample size
n = 3
y = sample(c(1:6), size = n1, replace = TRUE)
y = data.frame(matrix(y, ncol = n))
y$y_bar = apply(y, 1, mean)
hist(y$y_bar, breaks = 50)
library(dplyr)
iris %>%
group_by(Sex) %>%
group_map(~ broom::tidy(lm(Diameter ~ Whole.weight, data = .x)))
install.packages("moderndive")
library(caret)
version
install.packages('caret')
install.packages("caret")
install.packages("caret")
cm$overall[1]
source("C:/Users/snguyen4/Dropbox/git/math421/assignments/modeling_titanic.R")
library(tidyverse)
df = read_csv("https://bryantstats.github.io/math421/data/titanic.csv")
# Remove some columns
df <- df %>% select(-PassengerId, -Ticket, -Name, -Cabin)
# Set the target variable
df <- df %>% rename(target=Survived)
# Correct variables' types
df <- df %>%
mutate(target = as.factor(target),
Pclass = as.factor(Pclass),
)
# Handle missing values
# Replace NA of Age by its mean
mean_age <- mean(df$Age, na.rm=TRUE)
df$Age <- replace_na(df$Age, mean_age)
df = drop_na(df)
library(caret)
set.seed(2020)
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
model1 <- train(target~., data=df_train,
method = "glmnet")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "ranger")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
model1 <- train(target~., data=df_train,
method = "glmnet")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = ">50K")
model1 <- train(target~., data=df_train,
method = "glmnet")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "ranger")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "gam")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "gpls")
model1 <- train(target~., data=df_train,
method = "gamSpline")
model1 <- train(target~., data=df_train,
method = "gamSpline")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "gbm_h2o")
model1 <- train(target~., data=df_train,
method = "gbm_h2o")
model1 <- train(target~., data=df_train,
method = "knn")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "svmLinear3")
model1 <- train(target~., data=df_train,
method = "svmLinear3")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
model1 <- train(target~., data=df_train,
method = "lm")
model1 <- train(target~., data=df_train,
method = "avNNet")
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
cm$overall[1]
(2^4/24)*exp(-2)
df
df = read_csv("https://bryantstats.github.io/math421/data/titanic.csv")
library(tidyverse)
df = read_csv("https://bryantstats.github.io/math421/data/titanic.csv")
length(df)
nrow(df)
install.packages('randomForest')
version
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE)
library(RedditExtractoR)
library(tidytext)
library(ggpubr)
library(tidyverse)
library(knitr)
library(lubridate)
df <- find_thread_urls(sort_by="new", subreddit = 'college')
version
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE)
library(tidyverse)
library(tidytext)
library(knitr)
library(kableExtra)
df <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')
library(ggraph)
library(igraph)
library(ggraph)
library(widyr)
library(tidytext)
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, show_id, sort = TRUE) %>%
pairwise_count(word, show_id, sort = TRUE, upper = FALSE) %>%
filter(n<=50) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
geom_node_point(size = 5) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
theme_void()
