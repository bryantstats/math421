unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
inner_join(get_sentiments('bing'))
df %>%
filter(title=='Avengers: Infinity War') %>%
select(title, description) %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(word, sort = TRUE) %>%
inner_join(get_sentiments('nrc'))
?get_stopwords
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
get_stopwords() %>%
step_tfidf(description) %>%
prep()
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
get_stopwords(description) %>%
step_tfidf(description) %>%
prep()
?step_stopwords
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 5) %>%
step_tfidf(description) %>%
step_stopwords(description) %>%
step_normalize(all_numeric_predictors()) %>%
prep()
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
step_tfidf(description) %>%
step_stopwords(description) %>%
step_normalize(all_numeric_predictors()) %>%
prep()
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 10) %>%
step_stopwords(description) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
prep()
df %>%
unnest_tokens(input = description, output = word) %>%
anti_join(get_stopwords()) %>%
count(type, word, sort = TRUE) %>%
group_by(type) %>%
inner_join(get_sentiments("nrc")) %>%
filter(!is.na(sentiment)) %>%
count(sentiment, sort = TRUE) %>%
group_by(type) %>%
mutate(n = n/sum(n)) %>%
ggplot(aes(sentiment, n, fill=type))+geom_col(position = 'fill')+
labs(y='Relative Frequency', x ='')
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 10) %>%
step_stopwords(description) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 10) %>%
step_stopwords(description) %>%
step_tfidf(description) %>%
prep()
d1 <- juice(a)
kable(d1)
library(tidyverse)
library(tidytext)
library(knitr)
df <- readr::read_csv('data/netflix_titles.csv')
df %>%
head(2) %>%
kable()
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
head(2) %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 10) %>%
step_stopwords(description) %>%
step_tfidf(description) %>%
prep()
d1 <- juice(a)
kable(d1)
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 10) %>%
step_stopwords(description) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
df
df <- read_csv('data/netflix_titles.csv')
df <- df %>%
rename(target = type) %>%
select(target, description)
# Convert text data to numeric variables
a <- recipe(target~description,
data = df) %>%
step_tokenize(description) %>%
step_tokenfilter(description, max_tokens = 50) %>%
step_tfidf(description) %>%
step_normalize(all_numeric_predictors()) %>%
step_smote(target) %>%
prep()
d1 <- juice(a)
kable(d1)
1,990 *.12(82000-1990)
1990 + *.12(82000-1990)
1990 + .12*(82000-1990)
1990 + .12*(81000-1990)
9328+.22*(82000-81050)
1990 + .12*(81000-19900)
1990 + .12*(81000-19900)
9328+.22*(82000-81050)
1990 + .12*(70000-19900)
sd(1,2)
sd(1,2,3)
sd(c(1,2,3)_
sd(c(1,2,3))
sd(c(2,3,5,3,4,2,4,1,2))
x = c(2, 5, 10, 13, 18, 20, 24, 25, 27, 30)
mean(X)
mean(x)
sd(x)
2*9.57*3
x = c(2, 3,5,3,5,2,4,1,2,3)
sd(x)
2*sd(x)*3
a = as.matrix(c(1,2,3,4))
a
a = as.matrix(c(1,2,3,4),2,2)
a
as.matrix
as.matrix()
?as.matrix
a = as.matrix(c(1,2,3,4),col=2)
a
a = as.matrix(c(1,2,3,4),cols=2)
a
a = as.matrix(c(1,2,3,4),c(2,2))
a
a = as.matrix(c(1,2,3,4),ncol=2
)
a
a = as.matrix(c(1,2,3,4),ncol=2)
a
a = as.matrix(c(1,2,3,4),nrow=2)
a
a = as.matrix(c(1,2,3,4),nrow=2,ncol=2)
a
a = matrix(c(1,2,3,4),nrow=2,ncol=2)
a
a
eigen(a)
v=eigen(a)$vectors
v
t(v)%*%t
t(v)%*%v
v
v%*%t(v)
v=svd(a)
v
v=svd(a)$v
v
v%*%t(v)
pca(a)
prcomp(a)
v
a
svd(a)
?prcomp
prcomp(a, center = FALSE, scale. = FALSE)
svd(a)
library(tidyverse)
xa = 0
xb = 0
xc = 1
ya = 1
yb = 0
yc = 0
d = tibble(x = c(xa,xb,xc), y = c(ya,yb,yc), type = c('original'))
d[4,] = list(mean(d$x),mean(d$y),'mid_point')
ggplot(d, mapping = aes(x=x, y=y, color=type))+geom_point(size = 10)
# set the importance of the three points
wa = 3
wb = 2
wc = 1
# Set tuning-parameter alpha
# If alpha = 0, the three points have the same weight
# If alpha = 1, the new weights are the original weights
# If alpha < 1, relaxing on the weights (decrease the original weights)
# If alpha > 1, increase the original weights.
# If alpha < 0, it change the direction of the weights
# Tune this alpha to get the best alpha for the data
alpha = -1
# generate weights for the three points
n = 1000
u1 = runif(n)
u2 = runif(n)
u3 = runif(n)
ua = (wa^alpha)*u1
ub = (wb^alpha)*u2
uc = (wc^alpha)*u3
s = ua + ub + uc
va = ua/s
vb = ub/s
vc = uc/s
hist(va)
hist(vb)
hist(vc)
# generate synthetic points
xs = va*xa + vb*xb + vc*xc
ys = va*ya + vb*yb + vc*yc
d_synthetic = tibble(x = xs, y=ys, type ='synthetic')
df = rbind(d, d_synthetic)
ggplot(df, mapping = aes(x=x, y=y, color=type))+geom_point()
x=c(1:3,2)
x=seq(1,100,2)
x
x=seq(1,101,2)
x
x^x
sum(x^x)
x=c(1:100)
sum(x^100)
x=c(1:100)
y=c(2:101)
z=c(3:102)
1/(x*y*z)
sum(1/(x*y*z))
sum(1/(x*y))
tinytex::reinstall_tinytex()
options(htmltools.dir.version = FALSE)
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
df <-  read_csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
library(tidyverse)
df <-  read_csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
df
df %>% glimpse
str(df)
df
head(df)
head(df. 10)
head(df, 10)
?head
sum(is.na(df))
colSums(is.na(df))
df %>% is.na %>% colSums
10 %>% log
square(10)
squares(10)
cube(10)
10 %>% sin %>% cos
sum(x^2)
sum(log(c(1,2,3))
)
x <- c(1:10)
x %>% log %>% sum
x <- c(1:10)
sum(log(x))
df
df
options(htmltools.dir.version = FALSE)
by(df$New_deaths, df$WHO_region, mean)
?by
by(df$New_deaths, df$WHO_region, FUN=mean)
df
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
df
str(df)
df
head(df)
df$WHO_region
table(df$WHO_region)
head(df)
df$New_deaths2 <- cut(df$New_deaths,
breaks = c(-Inf, 2, 5,Inf),
labels=c('low_death','mid_death','high_death'))
table(df$New_deaths2)
df$New_deaths3 <- case_when(df$New_cases<2 ~ 'low_death',
df$New_cases<5 ~ 'mid_death',
TRUE~'high_death')
table(df$New_deaths3)
df$New_deaths3 <- case_when(df$New_deaths<2 ~ 'low_death',
df$New_deaths<5 ~ 'mid_death',
TRUE~'high_death')
table(df$New_deaths3)
table(df$New_deaths2)
df$New_cases2 <- case_when(df$New_cases==0 ~ 'No_new_cases',
TRUE ~ 'Has_new_cases')
table(df$New_cases2)
df$New_cases2 <- ifelse(df$New_cases==0,
'No_new_cases','Has_new_cases')
table(df$New_cases2)
df$New_deaths2 <- case_when(df$New_deaths<2 ~ 'low_death',
df$New_deaths<5 ~ 'mid_death',
TRUE~'high_death')
table(df$New_deaths2)
head(df)
names(df)
table(df$WHO_region)
str(df)
# Check type
class(df$Date_report)
str(df)
# Change type
df$Date_report = as.Date(df$Date_report)
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
names(df)[1] <- 'Date_report'
# Check type
class(df$Date_report)
str(df)
# Change type
df$Date_report = as.Date(df$Date_report)
# Change type
str(df)
?weekdays
?year
?years
years(df$Date_report)
library(lubridate)
years(df$Date_report)
table(years(df$Date_report))
month(df$Date_report)
?month
?month
# Create
df$month <- month(df$Date_report)
table(df$month)
df$month
class(df$month)
?month
class(df$month, label = TRUE)
library(lubridate)
class(df$month, label = TRUE)
month(df$month, label = TRUE)
detach(lubridate)
detach("package:lubridate", unload=TRUE)
options(htmltools.dir.version = FALSE)
df <-  read.csv('https://covid19.who.int/WHO-COVID-19-global-data.csv')
names(df)[1] <- 'Date_report'
# Check type
class(df$Date_report)
str(df)
# Change type
df$Date_report = as.Date(df$Date_report)
month(df$month, label = TRUE)
library(lubridate)
month(df$month, label = TRUE)
library(lubridate)
df$month <- month(df$Date_report, label = TRUE)
table(df$month)
?case_when
case_when
library(tidyverse)
case_when
table(df$month)
# Create a variable month
library(lubridate)
df$month <- month(df$Date_report, label = TRUE)
# group months into fewer categories
df$month2 <- case_when(df$month %in% c('Sep','Oct','Nov','Dec') ~ 'fall_semester',
df$month %in% c('Feb','Mar','Apr','May') ~ 'spring_semester',
TRUE~'break')
table(df$month2)
colSums(is.na(df))
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(message = FALSE, eval = FALSE)
xaringanExtra::use_tile_view()
xaringanExtra::use_tile_view()
install.packages('tidyverse')
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
library(tidyverse)
df <- read_csv('https://covidtracking.com/data/download/all-states-history.csv')
names(df)
table(df$dataQualityGrade)
df
start_time <- Sys.time()
df <- read.csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
end_time <- Sys.time()
end_time - start_time
df %>%
filter(date>'01-01-2021') %>%
group_by(state) %>%
summarise(average_deaths = mean(deaths)) %>%
arrange(-average_deaths)
df <- read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
# Select variable state and date for df1
df1 <-  select(df, state, date)
# Deselect variable state from df
df2 <-  select(df, -state)
# Select rows or days with no deaths
df3 <- filter(df, deaths==0, )
fg
df
# conventional way
df1 = group_by(df, state)
summarise(df1, summarise(mean(deaths)))
df1 = group_by(df, state)
df1
summarise(df1, summarise(mean(deaths)))
# Pipe
df %>%
group_by(state) %>%
summarise(mean(deaths))
# conventional way
df1 = filter(df, date>'01-01-2021')
df2 = group_by(df1, state )
summarise(df2, summarise(mean(deaths)))
# Pipe
df %>%
filter(date>'01-01-2021') %>%
group_by(state) %>%
summarise(mean(deaths))
summarise(df1, summarise(mean(deaths)))
# conventional way
df1 = group_by(df, state)
summarise(df1, summarise(mean(deaths)))
df %>%
group_by(state) %>%
summarise(mean(deaths))
df
# conventional way
df1 = group_by(df, state)
df1
summarise(df1, summarise(mean(deaths)))
summarise(df1, summarise(mean(cases)))
?count
df %>% count(cases)
df %>% filter(state=='Rhode Island') %>% count(cases)
df %>% filter(state=='Rhode Island') %>% count(cases) %>% arrange(n)
df %>% filter(state=='Rhode Island') %>% count(cases) %>% arrange(-n)
df <- read_csv(../data/titanic.csv)
df <- read_csv('../data/titanic.csv')
df
df %>% count(Pclass)
df %>% count(Embarked)
library(tidyverse)
df <- read_csv('titanic_missing.csv')
setwd("C:/Users/sonou/Dropbox/git/math421")
setwd("C:/Users/sonou/Dropbox/git/math421/data")
df <- read_csv('titanic_missing.csv')
df
